{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from docs.test.zwplib import LakeHouse\n",
    "\n",
    "# import liblakehouse\n",
    "from liblakehouse import LakeHouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be166f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakehouse = LakeHouse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# landing tier\n",
    "import requests\n",
    "\n",
    "url = 'https://servicodados.ibge.gov.br/api/v3/agregados/7060/periodos/202001/variaveis/63|69|2265|66?localidades=N1[all]|N6[all]&classificacao=315[all]'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('ipca_amplo.json', 'wb') as bf:\n",
    "    bf.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fefbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakehouse.write_files(catalog='landing', schema='ibge', volume='ipca_amplo', files=['ipca_amplo.json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bdf200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bronze tier\n",
    "df = lakehouse.read_files(\n",
    "    catalog=\"landing\",\n",
    "    schema=\"ibge\",\n",
    "    volume=\"ipca_amplo\",\n",
    "    files=[\n",
    "        {\n",
    "            \"path\": \"ipca_amplo.json\",\n",
    "            \"format\": \"json\",\n",
    "            \"schema\": \"\",\n",
    "            \"options\": {},\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60561a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c24fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakehouse.write_table(\n",
    "    catalog=\"bronze\",\n",
    "    schema=\"ibge\",\n",
    "    table=\"ipca_amplo\",\n",
    "    dataframe={\n",
    "        \"dataframe\": df[0],\n",
    "        \"format\": \"delta\",\n",
    "        \"mode\": \"overwrite\",\n",
    "        \"partition_by\": [],\n",
    "        \"options\": {\"overwriteSchema\": \"true\"},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b554a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# silver tier\n",
    "df = lakehouse.read_table(\n",
    "    catalog=\"bronze\",\n",
    "    schema=\"ibge\",\n",
    "    table=\"ipca_amplo\",\n",
    "    options={\n",
    "        \"format\": \"delta\",\n",
    "        \"options\": {}\n",
    "    }    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b20798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a155c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakehouse.write_table(\n",
    "    catalog=\"silver\",\n",
    "    schema=\"ibge\",\n",
    "    table=\"ipca_amplo\",\n",
    "    dataframe={\n",
    "        \"dataframe\": df,\n",
    "        \"format\": \"delta\",\n",
    "        \"mode\": \"overwrite\",\n",
    "        \"partition_by\": [],\n",
    "        \"options\": {\"overwriteSchema\": \"true\"},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25/08/21 07:54:12 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
    "# SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
    "# SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
    "# SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
    "\n",
    "# 25/08/21 07:54:15 WARN HiveClientImpl: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic\n",
    "# Hive Session ID = e38db77a-6afe-437e-bc8e-d5fa7f632b38\n",
    "# 25/08/21 07:54:43 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
    "# 25/08/21 07:54:51 WARN S3ABlockOutputStream: Application invoked the Syncable API against stream writing to numbers/integer/part-00000-8c5f40d3-4def-4580-b432-fc63efb209cc-c000.snappy.parquet. This is Unsupported\n",
    "# 25/08/21 07:55:02 WARN HiveExternalCatalog: Could not alter schema of table `numbers`.`integer` in a Hive compatible way. Updating Hive metastore in Spark SQL specific format.\n",
    "\n",
    "# Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:34253\n",
    "\n",
    "# WARN HiveClientImpl: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32bff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create catalog bronze using delta_lake with (\n",
    "#     \"hive.metastore.uri\"='thrift://host.docker.internal:9083',\n",
    "#     \"s3.aws-access-key\"='9a5edc7df42cfd71',\n",
    "#     \"s3.aws-secret-key\"='DW4CyCit2CGO9gXyRtqQ7Lj6ZzQZm3xfS33ItBQpVbc=',\n",
    "#     \"s3.endpoint\"='http://host.docker.internal:10000',\n",
    "#     \"s3.region\"='us-east-1',\n",
    "#     \"fs.native-s3.enabled\"='true',\n",
    "#     \"s3.path-style-access\"='true',\n",
    "#     \"delta.metastore.store-table-metadata\"='true',\n",
    "#     \"delta.register-table-procedure.enabled\"='true',\n",
    "#     \"delta.deletion-vectors-enabled\"='true',\n",
    "#     \"delta.enable-non-concurrent-writes\"='true'\n",
    "# )\n",
    "\n",
    "# create schema if not exists number with (\n",
    "#     \"location\" = 's3a://bronze/numbers'\n",
    "# )\n",
    "\n",
    "# CALL bronze.system.register_table(schema_name => 'numbers', table_name => 'integers', table_location => 's3://bronze/numbers/integergs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Git Commit Message Convention for Your Team\n",
    "\n",
    "# https://medium.com/@naandalist/creating-a-git-commit-message-convention-for-your-team-acb4b3edfc44"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto-lakehouse (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
